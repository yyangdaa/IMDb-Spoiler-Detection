
# IMDbâ€‘Spoilerâ€‘Detection

**Automatically detect untagged spoilers in IMDb user reviews**  
Using both classical ML (TFâ€‘IDF + Logistic Regression / XGBoost) and a Transformer (DistilBERT) approach.

---

## ğŸ“ Repository Structure

```

.
â”œâ”€â”€ IMDb\_movie\_details.json   # Raw review + metadata dump from IMDb
â”œâ”€â”€ data\_preprocessing.py     # Clean & featureâ€‘engineer script
â”œâ”€â”€ basic-model.ipynb         # Baseline models (TFâ€‘IDF + LR / XGBoost)
â”œâ”€â”€ transformer.ipynb         # Transformerâ€‘based classifier (DistilBERT)
â””â”€â”€ README.md                 # You are here

````

---

## âš™ï¸ Setup

1. **Clone & install**  
   ```bash
   git clone https://github.com/yourusername/IMDbâ€‘Spoilerâ€‘Detection.git
   cd IMDbâ€‘Spoilerâ€‘Detection
   pip install pandas scikit-learn xgboost transformers torch jupyter matplotlib


2. **Create a data folder**

   ```bash
   mkdir data results
   ```

---

## ğŸ§¹ 1. Data Preprocessing

Run the Python script to:

* Clean & normalize review text
* Compute TFâ€‘IDF vectors
* Engineer simple metadata features (review length, genre, timestamp, etc.)
* Output a single CSV ready for modeling

```bash
python data_preprocessing.py \
  --input IMDb_movie_details.json \
  --output data/processed_reviews.csv
```

---

## ğŸ¤– 2. Baseline Models

Open the baseline notebook:

```bash
jupyter notebook basic-model.ipynb
```

Inside you will:

1. Load `data/processed_reviews.csv`
2. Split into train / test sets
3. Train & evaluate:

   * Logistic Regression (TFâ€‘IDF)
   * XGBoost (TFâ€‘IDF + metadata)
4. View metrics (accuracy, precision, recall, F1) and confusion matrices
5. Export results to `results/baseline/`

---

## ğŸ”¥ 3. Transformer Model

Launch the Transformer notebook:

```bash
jupyter notebook transformer.ipynb
```

It walks through:

1. Tokenizing reviews for DistilBERT
2. Fineâ€‘tuning on spoiler classification
3. Evaluating against your baseline
4. Plotting training curves & ROC

Results will be saved under `results/transformer/`.

---

## ğŸ“Š Viewing Results

After running both notebooks, check:

```
results/
â”œâ”€â”€ baseline/
â”‚   â”œâ”€â”€ metrics.json
â”‚   â””â”€â”€ confusion_matrix.png
â””â”€â”€ transformer/
    â”œâ”€â”€ metrics.json
    â””â”€â”€ training_loss.png
```

---

## ğŸ“ License

This project is MITâ€‘licensed. See [LICENSE](LICENSE) for details.

```

Feel free to adjust the `--output` path in `data_preprocessing.py` or notebook cells if your scripts save to a different location.
```
